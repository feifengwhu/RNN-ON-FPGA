\documentclass[a4paper, onecolumn, 10pt]{article}

    %%--Input Português/(...)--%%
    \usepackage[portuguese]{babel}
    \usepackage[utf8]{inputenc}

    %%--Packages Opcionais--%%
    \usepackage{graphicx}
    \usepackage{epstopdf}
    \usepackage{textcomp}
    \usepackage{amsmath}
    \usepackage{amstext}
    \usepackage{SIunits}
    \usepackage{pgfplots}
    \usepackage{float}
    \usepackage[scale=0.80]{geometry}
    \usepackage{enumerate}
    \usepackage{subfig}
    \usepackage{tabularx}
    \usepackage{xcolor}
    \usepackage[colorlinks=true,urlcolor=blue,linkcolor=magenta]{hyperref}
    \usepackage{listings}
    \DeclareMathOperator*{\argmax}{\mathbf{arg\,max\,\,}}

    %%--Gestão de Referências Bibliográficas--%%
    \usepackage[backend=biber, style=ieee]{biblatex}
    \addbibresource{references.bib}
    %%--Packages de Tipos de Letra--$$
    \usepackage[mathscr]{euscript} 
    %\renewcommand*\ttdefault{pcr}
    \usepackage{libertine}
    %\usepackage{mathptmx}
    \usepackage{inconsolata}
    \usepackage{carlito}
    %%-- Customizing the Code Presentation -- %%
    \definecolor{codegreen}{rgb}{0,0.6,0}
    \definecolor{codegray}{rgb}{0.5,0.5,0.5}
    \definecolor{codepurple}{rgb}{0.58,0,0.82}
    \definecolor{backcolour}{rgb}{0.95,0.95,0.92}
    \definecolor{sectioncol}{HTML}{9C0906}
    \definecolor{subsectioncol}{HTML}{CC100C}


	\lstdefinestyle{mystyle}{
	backgroundcolor=\color{backcolour},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	numberstyle=\ttfamily\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\ttfamily\scriptsize,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=2
	}
    \lstset{style=mystyle}

    %%--Cabeçalho de Rodapé--%%
    \usepackage{fancyhdr}
    \pagestyle{fancy}
    \cfoot{\large\thepage}
    \rfoot{}
    \lhead{}
    \chead{}
    \rhead{}
    \renewcommand{\headrulewidth}{0.5pt}
    \renewcommand{\footrulewidth}{0.5pt}
    \newcommand{\mc}[1]{\mathcal{#1}}	
    \newcommand{\mb}[1]{\mathbf{#1}}	
    \newcommand{\prob}[1]{\mathrm{P}\left( #1 \right)}
    \newcommand{\compon}{X_1 = x_1^{(k)}, X_2 = x_2^{(k)}, \dots, X_D = x_D^{(k)}}
    \newcommand{\prodBay}{\prod_{i=1}^{D} \prob{X_i = x_i^{(k)} | Y = c_j }}
    	%%--Estilo das Secções--%%
    \usepackage[sf]{titlesec}    

    \titlespacing{\section}{0em}{2.5em}{2em}
    \titleformat{\section}
    {\color{sectioncol}\sffamily\scshape\Large\bfseries}
    {\color{sectioncol}\LARGE\thesection}{1em}{}
    
    \titlespacing{\subsection}{1em}{1.5em}{1em}
    \titleformat{\subsection}
    {\color{subsectioncol}\sffamily\slshape\normalsize\bfseries}
    {\color{subsectioncol}\thesubsection \hspace{5pt} -- }{5pt}{}
    
    \titlespacing{\subsubsection}{2em}{1.5em}{1em}
    \titleformat{\subsubsection}
    {\color{subsectioncol}\sffamily\slshape\normalsize}
    {\color{subsectioncol}\thesubsubsection \hspace{5pt} -- }{5pt}{}

    \title{\Huge PDI -- Relatório de Progresso}
    \author{\itshape \href{mailto:ee11126@fe.up.pt}{José Pedro Castro Fonseca}   } 
    
\begin{document}

\pagestyle{plain}

\begin{figure}
	\centering
	\includegraphics[scale=0.3]{logo_feup.eps}
\end{figure}
\sffamily
\maketitle

%\vspace{80pt}

%\begin{titlepage}
%\sffamily
%	{\huge\bfseries Machine Learning -- Homework 2} \\
%	\vspace{20pt}
%	{\large\itshape  José Pedro Castro Fonseca} \\
%	\vspace{15pt}
%	{\bfseries November 2, 2015 -- Porto, Portugal} \\
%\end{titlepage}

%\maketitle
\rmfamily\pagestyle{fancy}
\begin{center}
	\Large \textit{Dynamically Reconfigurable Multi-Classifier Architecture on FPGA}
\end{center}
\section{Análise Introdutória do Problema a Tratar}\label{sec:analiseProb}
Esta Tese de Dissertação consistirá no projeto e implementação de um Acelerador de Hardware reconfigurável -- baseado em FPGA\footnote{\textit{Field-Programmable Gate Array}, um tipo de Circuitos Integrados reconfiguráveis em Software, cuja estrutura é \textbf{descrita} usando linguagens como Verilog ou VHDL} -- para estruturas de Aprendizagem Computacional, nomeadamente \textbf{Redes Neuronais Recursivas}. 	
	\subsection{Contexto}
	As \textbf{Redes Neuronais Artificiais} são uma das estruturas de aprendizagem mais populares do mundo da Inteligência Artificial. Tal como o nome sugere, são estruturas cuja operação é inspirada na forma como os blocos constituintes do nosso cérebro, os neurónios, operam. Apesar da sua elevada performance, um dos seus \textit{shortcomings} é o facto de não conseguirem reter informação de eventos anteriores na sua decisão atual, i.e. perante um vetor de entrada $x_i$, a decisão sobre o vetor de saída $y_i$ não possui influência direta de entradas anteriores $x_{i-1}, x_{i-2}, ...$, sendo assim desajustada para o processamento de séries temporais de dados, em que entradas atuais têm uma elevada dependência informacional e sintatica de entradas anteriores, como na análise de texto, e a predição de valores futuros de sinais deterministicos.

	Uma das formas de melhorar o aspeto anterior, foi a introdução nos anos 80 de \textbf{elementos de memória}, sendo isto feito atrvés do \textit{feedback} das camadas exteriores de decisão para as camadas interiores, ou escondidas. A estrutura que utilizarei neste trabalho serão as \textit{Long Short-Term Memory Networks} \autocite{hochreiter-lstm}, propostas por Hochreiter et al. em 1997, e que desde então é uma das técnicas \textit{state-of-the-art} na área da Aprendizagem Profunda (\textit{Deep Learning}), tendo obtido a melhor classificação de sempre no reconhecimento de caligrafia \autocite{hochreiter-hrr} em 2009, reconhecimento de fala \autocite{speechRec-lstm}, entre outros.  

	\subsection{Motivação}
	Todas estas técnicas são geralmente implementadas em Processadores Convencionais, fazendo uso de linguagens de alto ou baixo nível. Desta forma, todo o paralelismo real inerente às estruturas de cálculo fica limitado ao número de \textit{cores} físicos presentes na máquina, que hoje em dia não excedem os 4 ou 8 nos dispositivos convencionais usados pela maioria das pessoas (Computadores Pessoais ou dispositivos móveis). Assim, de forma a paralelizar completamente a estrutura e, por conseguinte, aumentar consideravelmente a performance, uma solução é a utilização de uma GPU ou FPGA, perimitindo a realização de aprendizagens cada vez mais complexas, e cada vez mais depressa. Além disso, quando a taxa de amostragem de dados de entrada é muito elevada, a solução convencional de CPU não é escalavel e apresenta sérias limitações. 
	
	Apesar de já haver trabalho de adaptação de outros algoritmos de aprendizagem para Hardware, a área do \textit{Deep Learning} ainda é um campo pouco explorado no Hardware, sendo que no caso específico de LSTM, ainda existe apenas um artigo \autocite{fpgalstm}, submetido ainda este mês, que explora uma primeira implementação desta técnica em FPGA para a geração automática de texto. 
	
	Ainda que os CPU's convencionais sejam insubstituíveis para as funções normais a que geralmente estão afetos, é possível que possam haver co-processadores baseados nestas estruturas que acelerem certas tarefas de reconhecimento automático, sem comprometer a performance do sistema global. Além disso, foi provado  que as Redes Neuronais Recorrentes são \textit{Turing Complete} \autocite{turingcompletenessRNN}\autocite{turingcompletenessRNN2}, significando, por isso, que podem simular o funcionamento de qualquer programa que possa ser executado num CPU convencional.

	\subsection{Objetivos}
	Assim, tendo como base o trabalho apresentado em \autocite{fpgalstm}, a ideia é construir um sistema que, além daquele, permita uma reconfiguração completa, em tempo real, da topologia da rede, e a subsituição das células básicas por outras com variações na sua estrutura.
	
	Será feito, em primeiro lugar, um modelo conceptual do sistema numa linguagem de alto-nível que permita validar o funcionamento dos IP Cores que forem posteriormente desenvolvidos em Verilog, e que depois serão sintetizados para a plataforma-alvo FPGA. Além disso, será utilizado um ou dois \textit{Benchmarks} conhecidos para, por um lado, comparar o desempenho do sistema FPGA versus a implementação em CPU e, por outro, comparar o desempenho da minha implementação com outros desempenhos de referência. Seria igualmente interessante escolher uma aplicação-tipo destas Redes, e testá-la na minha implementação, para poder observar o seu funcionamento prático.
	

\section{Trabalho Realizado}
Nesta secção é feita uma pequena demonstração das interações com o Orientador, assim como os eventos anteriores à atribuição do tema de dissertação que motivaram a proposta do mesmo.

	\subsection{Pessoas Envolvidas na Dissertação}
	Para além de mim, o Candidato ao grau de Mestre, incluem-se duas pessoas, nomeadamente

	\begin{itemize}
		\item
			\textbf{Orientador --} O \href{https://sigarra.up.pt/feup/pt/func_geral.formview?p_codigo=210963}{Professor João Canas Ferreira}, professor Auxiliar do Departamento de Engenharia Eletrotécnica e de Computadores da Faculdade de Engenharia da Universidade do Porto, e meu antigo docente da UC de \href{https://sigarra.up.pt/feup/pt/UCURR_GERAL.FICHA_UC_VIEW?pv_ocorrencia_id=352359}{Projeto de Circuitos VLSI}.
		\item
			\textbf{Co-Orientador --} O \href{http://www.cl.cam.ac.uk/~ijpdmt2/}{Ivo Timóteo}, candidato a PhD em Ciência de Computadores, na área de Inteligência Artificial, na Universidade de Cambridge, Reino Unido.
	
	\end{itemize}	


	\subsection{Instâncias de Interação com o Orientador}
	As principais instâncias de interação com o orientador resumem-se nos seguintes pontos.
	\begin{itemize}
		\item
			\textbf{Sondagem dos Temas Disponíveis (4 de Setembro de 2015) --} Após me ter inscrito à UC de \href{https://sigarra.up.pt/feup/pt/ucurr_geral.ficha_uc_view?pv_ocorrencia_id=374787}{Aprendizagem Computacional}, comecei a navegar um pouco pelo mundo das aplicações do Machine Learning e da forma como este pode ser acelerado com estruturas de Hardware dedicadas, ao invés de utilizar Processadores convencionais. Adicionalmente, colegas de anos anteriores sugeriram-me que o Prof. João Canas Ferreira poderia ter algum trabalho disponível nessa área. Assim, enviei um email ao Prof. João Canas Ferreira para sondar os temas que teria disponíveis nesta área, e obtive resposta positiva. Combinamos, então, uma reunião Skype em que discutiriamos com mais detalhe esta hipótese, no dia 15 de Setembro.

		\item
			\textbf{Reunião por Skype (15 de Setembro de 2015) --} Nesta reunião, o Prof. Canas deu-me a conhecer alguns projetos em concreto que tinha em mente, e a abordagem ao problema que deveria ser seguida. Acordamos, então, que ele iria submeter uma \href{https://sigarra.up.pt/feup/pt/estagios_empresas.ver_dados_proposta?p_id=191431&pv_perfil=ALU&p_aluno_id=116261}{Proposta de Tema de Dissertação}, mas não seria imediatamente alocada para mim, dado que eu gostaria de dar uma vista de olhos pelos restantes Temas, e só depois tomar uma decisão final, dado que a minha média me permitiria escolher o tema em concurso normal, sem o problema de eu ser afastado pelo processo de seriação.

		\item
			\textbf{Envio da Proposta de Dissertação (17 de Setembro de 2015) --} Envio, por email, da proposta de dissertação redigida pelo Prof. Canas, para minha análise. Esta proposta é uma indicação geral do trabalho a ser desenvolvido, sendo que o algoritmo específico e o equipamento utilizado poderiam sofrer modificações com o desenrolar da pesquisa.

		\item
			\textbf{Submissão da minha lista de preferências no Concurso Normal (27 de Setembro de 2015) --} Neste dia, submeto a minha lista de preferências de escolha de tema de dissertação, em que me decido definitivamente por este tema. Informei o Prof. Canas, por email, da minha escolha. Sugiro a possibilidade de se incluir como co-orientador o Ivo Timóteo.

		\item
			\textbf{Reunião Presencial (5 de Novembro de 2015) --} Discussão do plano de trabalhos, dos objetivos a serem atingidos e das metodologias a serem desenvolvidas. Nesta reunião, apresentei também alguns resultados preliminares da minha primeira pesquisa sobre a matéria, e o Orientador sugere, adicionalmente, a incorporação dos eventuais resultados da dissertação num projeto em desenvolvimento no INESC, como uma possibilidade.

		\item
			\textbf{Reunião Presencial (26 de Novembro de 2015) --} Neste dia, apresento uma versão preliminar deste relatório ao Orientador para discussão, assim como uma primeira ideia de trabalho, explicada na Secção~\ref{sec:analiseProb}.
	\end{itemize}

	\subsection{Sequência Temporal de Trabalhos}
	Toda a frequência da UC de Aprendizagem de Computacional foi uma oportunidade de me inteirar das diferentes técnicas da área. Após este conhecimento básico, passei uma boa parte do mês de Outubro a fazer uma pesquisa sobre implementações destas técnicas em Hardware, e descobri que as técnicas básicas iniciais de SVM e Médias k-NN -- presentes na proposta inicial -- são já bastante trabalhadas, sendo científicamente mais interessante escolher uma nova área de foco.

	Assim, depois da primeira reunião presencial com o Orientador, foquei-me durante o mês de Novembro em encontrar técnicas que, apesar de serem estado-da-arte, não tivessem sido exploradas na vertente de implementação em hardware, ou em caso positivo, isso estivesse ainda no começo: depois de uma pesquisa no site \href{http://www.engineeringvillage.com/}{\textit{Engineering Village}}, fui conduzido a estas técnicas de Redes Neuronais Recorrentes. Procurei, também, informação de alto nível no \href{http://people.idsia.ch/~juergen/rnn.html}{site} do Prof. Jürgen Schmidhuber (\textit{Università della Svizzera italiana}, Suiça), um dos autores das \textit{Long Short-Term Memory Networks}. Após esta fase preliminar de recolha de informação, e de ter trocado impressões com o Orientador e o Co-Orientador, sintetizei toda essa informação neste Relatório de Progresso.

	\section{Pontos a Concretizar no Relatório Seguinte}
	Para o Relatório Final de PDI, é necessário fazer um levantamento exaustivo de todo o estado da arte neste tipo de redes, bem como uma pesquisa bibliográfica que permita compreender mais a fundo os seus detalhes teóricos, o que será de extrema importância para conseguir reproduzi-las eficazmente em hardware.

	Além disso, é necessário identificar a melhor \textit{framework} para desenvolver o modelo conceptual de alto-nível, permitindo assim uma implementação eficiente e comparável com o restante trabalho já existente na área, assim como dos \textit{benchmarks} mais adequados para testar a eficiência da implementação hardware. Por último, convém seleccionar uma aplicação (numa área de reconhecimento de fala, produção músical, entre outras) que permita justificar a pertinência da aplicação prática desta implementação.

	\printbibliography
\end{document}
