\begin{thebibliography}{10}

\bibitem{Graves05}
Alex Graves and Jürgen Schmidhuber.
\newblock Framewise phoneme classification with bidirectional lstm and other
  neural network architectures.
\newblock {\em Neural Networks}, pages 5--6, 2005.

\bibitem{Bishop2006}
Christopher~M. Bishop.
\newblock {\em Pattern Recognition and Machine Learning (Information Science
  and Statistics)}.
\newblock Springer-Verlag New York, Inc., Secaucus, NJ, USA, 2006.

\bibitem{Bengio1991}
Yoshua Bengio.
\newblock {\em Artificial Neural Networks and Their Application to Sequence
  Recognition}.
\newblock PhD thesis, McGill University, Montreal, Que., Canada, Canada, 1991.
\newblock UMI Order No. GAXNN-72116 (Canadian dissertation).

\bibitem{Yoshua01}
Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber.
\newblock Gradient flow in recurrent nets: the difficulty of learning long-term
  dependencies.
\newblock 2001.

\bibitem{Yoshua94}
Yoshua Bengio, Patrice Simard, and Paolo Frasconi.
\newblock Learning long-term dependencies with gradient descent is difficult.
\newblock {\em IEEE Transactions on Neural Networks}, 5(2):157 -- 166, 1994.
\newblock Gradient based learning algorithms;Information latching;Input/output
  sequences;Learning algorithms;Parametric dynamical system;Recurrent neural
  network training;Temporal contingencies;.

\bibitem{Hoch97}
S.~Hochreiter and J.~Schmidhuber.
\newblock Long short-term memory.
\newblock {\em Neural Computation}, 9(8):1735 -- 80, 1997.

\bibitem{Gers00}
F.A. Gers, J.~Schmidhuber, and F.~Cummins.
\newblock Learning to forget: continual prediction with lstm.
\newblock {\em Neural Computation}, 12(10):2451 -- 71, 2000.
\newblock LSTM;learning algorithms;recurrent neural networks;LSTM
  networks;continual input streams;forget gate;.

\bibitem{Gers2000}
F.A. Gers and J.~Schmidhuber.
\newblock Recurrent nets that time and count.
\newblock volume vol.3, pages 189 -- 94, Los Alamitos, CA, USA, 2000.
\newblock recurrent neural networks;RNN;timing;counting;time
  intervals;sequential tasks;motor control;rhythm detection;long short-term
  memory;LSTM;peephole connections;internal cells;multiplicative gates;discrete
  time steps;stable sequences;highly-nonlinear precisely-timed spike
  sequences;.

\bibitem{Greff15}
Klaus Greff, Rupesh~Kumar Srivastava, Jan Koutn{\'{\i}}k, Bas~R. Steunebrink,
  and J{\"{u}}rgen Schmidhuber.
\newblock {LSTM:} {A} search space odyssey.
\newblock {\em CoRR}, abs/1503.04069, 2015.

\bibitem{Spall98}
J.C. Spall.
\newblock Adaptive stochastic approximation by the simultaneous perturbation
  method.
\newblock volume vol.4, pages 3872 -- 9, Piscataway, NJ, USA, 1998.
\newblock stochastic approximation;loss functions;stochastic
  search;Newton-Raphson algorithm;Hessian matrix;iterative
  method;optimization;root-finding;parameter estimation;adaptive estimation;.

\bibitem{Maeda05}
Y.~Maeda and M.~Wakamura.
\newblock Simultaneous perturbation learning rule for recurrent neural networks
  and its fpga implementation.
\newblock {\em IEEE Transactions on Neural Networks}, 16(6):1664 -- 72, 2005.
\newblock perturbation learning rule;recurrent neural network;FPGA;dynamic
  information processing;feedforward neural network;recursive learning
  scheme;correlation learning;analog learning;oscillatory solution;hardware
  implementation;Hopfield neural network;field-programmable gate array;.

\end{thebibliography}
