Automatically generated by Mendeley Desktop 1.15.2
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Yao2014,
abstract = {Neural network based approaches have recently produced record-setting performances in natural language understanding tasks such as word labeling. In the word labeling task, a tagger is used to assign a label to each word in an input sequence. Specifically, simple recurrent neural networks (RNNs) and convolutional neural networks (CNNs) have shown to significantly outperform the previous state-of-the-art - conditional random fields (CRFs). This paper investigates using long short-term memory (LSTM) neural networks, which contain input, output and forgetting gates and are more advanced than simple RNN, for the word labeling task. To explicitly model output-label dependence, we propose a regression model on top of the LSTM un-normalized scores. We also propose to apply deep LSTM to the task. We investigated the relative importance of each gate in the LSTM by setting other gates to a constant and only learning particular gates. Experiments on the ATIS dataset validated the effectiveness of the proposed models. {\&}copy; 2014 IEEE.},
author = {Yao, Kaisheng and Peng, Baolin and Zhang, Yu and Yu, Dong and Zweig, Geoffrey and Shi, Yangyang},
doi = {10.1109/SLT.2014.7078572},
journal = {2014 IEEE Workshop on Spoken Language Technology, SLT 2014 - Proceedings},
month = {apr},
pages = {189--194},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Spoken language understanding using long short-term memory neural networks}},
url = {http://www.engineeringvillage.com/blog/document.url?mid=cpx{\_}M15808ef714d300bc1b6M56c210178163171{\&}database=cpx},
year = {2014}
}
@article{Landsiedel2011,
abstract = {Segmentation of speech signals is a crucial task in many types of speech analysis. We present a novel approach at segmentation on a syllable level, using a Bidirectional Long-Short-Term Memory Neural Network. It performs estimation of syllable nucleus positions based on regression of perceptually motivated input features to a smooth target function. Peak selection is performed to attain valid nuclei positions. Performance of the model is evaluated on the levels of both syllables and the vowel segments making up the syllable nuclei. The general applicability of the approach is illustrated by good results for two common databases-Switchboard and TIMIT-for both read and spontaneous speech, and a favourable comparison with other published results.},
author = {Landsiedel, C. and Edlund, J. and Eyben, F. and Neiberg, D. and Schuller, B.},
journal = {2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
publisher = {IEEE, Piscataway, NJ, USA},
title = {{Syllabification of conversational speech using bidirectional long-short-term memory neural networks}},
url = {http://www.engineeringvillage.com/blog/document.url?mid=inspec{\_}ef55021323fe8cd56M773f2061377553{\&}database=ins},
year = {2011}
}
