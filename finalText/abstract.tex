\chapter*{Resumo}
\addcontentsline{toc}{chapter}{Resumo}

Esta dissertação tem como objetivo a implementação em FPGA de uma Rede Neuronal \textit{Long Short-Term Memory} (LSTM).

As redes neuronais são uma das técnicas mais usadas na área da Aprendizagem Computacional Profunda.
Esta rede em particular, a LSTM, é uma rede recursiva, na medida em que a saída
da cada neurónio, num instante de tempo, \emph{também} serve de entrada no instante de tempo seguinte, e
os seus elementos de memória conseguem recordar padrões em sequências de dados,
apresentando vantagens claras, neste campo, face a redes neuronais convencionais.

As aplicações das Redes Neuronais são inúmeras, como se poderá atestar no capítulo
que faz o levantamento do estado-da-arte. Embora a implementação em \textit{software}
seja a solução comum para todas estas arquitecturas, as implementações em \textit{hardware}
são ainda poucas e os benefícios do paralelismo inerente a uma plataforma de \textit{hardware} dedicado não
são aproveitados. É nesse enquadramento que este trabalho se posiciona, apresentando uma implementação inédita de LSTM em FPGA,
fazendo apenas uso de recursos internos à mesma, apresentando um \textit{speed-up} de 251 vezes face
a uma implementação \textit{software} --- executada num Computador de alta \textit{performance} --- assim como a
proposta de um circuito auxiliar que permita fazer o treino \textit{on-chip} da rede, usando um método de perturbações
estocásticas simultâneas (SPSA).


\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}

The objective of this Dissertation work is to implement a Long Short-Term Memory (LSTM) Neural
Network in an FPGA platform.

Neural Networks are one of the most commonly used techniques in Deep Learning.
This particular type of network, as LSTM Network, is a recursive network, given that the neuron outputs in a
given time are \emph{also} fed as the input in the next time step and, that way, their memory elements can
make sense of patterns within data sequences, unlike conventional neural networks.

This type of network, as well as many other kinds of networks, have been profusely implemented
in software, and their practical applications are plentiful, as one can attest
in the State of the Art chapter. However, there are only few FPGA implementation of these algorithms, and the benefits of the inherent
parallelism offered by a dedicated hardware platform are not availed. This work, then, implements an LSTM Network in FPGA, using only
its internal resources, and achieving a $251 \times$ \textit{speed-up} in processing time when compared to a software implementation,
running on a high-end Desktop. A circuit that will allow on-chip training for this network, using simultaneous stochastic perturbations (SPSA),
is also proposed.
